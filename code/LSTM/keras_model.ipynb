{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# math\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from numpy import mean\n",
    "\n",
    "# graph and table\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import pandas as pd\n",
    "\n",
    "# other\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import holidays\n",
    "\n",
    "# option\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "#Den Bosch flow\n",
    "path = \"../data/sewer_data/data_pump/RG8150/RG8150/\"\n",
    "path1 = \"../sewer_data_db/data_wwtp_flow/RG1876_flow/\"\n",
    "path2 = \"../sewer_data_db/data_wwtp_flow/RG1882_flow/\"\n",
    "\n",
    "\n",
    "#Bokhoven level\n",
    "path3 = \"../data/sewer_data/data_pump/RG8180_L0/\"\n",
    "#Bokhoven flow\n",
    "path4 = \"../data/sewer_data/data_pump/RG8180_Q0/\"\n",
    "\n",
    "\n",
    "#Haarsteeg level\n",
    "path5 = \"../data/sewer_data/data_pump/rg8170_N99/\"\n",
    "#Haarsteeg flow\n",
    "path6 = \"../data/sewer_data/data_pump/rg8170_99/\"\n",
    "\n",
    "\n",
    "#Helftheuvelweg level column 003 Helftheuvelweg *.csv\n",
    "path7 = \"../data/sewer_data_db/data_pump_level/\"\n",
    "#Helftheuvelweg flow \n",
    "path8 = \"../data/sewer_data_db/data_pump_flow/1210FIT301_99/\"\n",
    "\n",
    "\n",
    "#Engelerschans level column “004 Engelerschans” *.csv\n",
    "path9 = \"../data/sewer_data_db/data_pump_level/\"\n",
    "#Engelerschans flow + Haarsteeg + Bokhoven, therefore substract for only Engeleschans\n",
    "path10 = \"../data/sewer_data_db/data_pump_flow/1210FIT201_99/\"\n",
    "\n",
    "\n",
    "#Maaspoort level Column: “006 Maaspoort” *.csv \n",
    "path11 = \"../data/sewer_data_db/data_pump_level/\"\n",
    "#Maasport flow + Rompert\n",
    "path12= \"../data/sewer_data_db/data_pump_flow/1210FIT501_99/\"\n",
    "\n",
    "\n",
    "#Oude Engelenseweg level Column: “002 Oude Engelenseweg” *.csv\n",
    "path13 = \"../data/sewer_data_db/data_pump_level/\"\n",
    "#Oude Engelenseweg flow\n",
    "path14 = \"../data/sewer_data_db/data_pump_flow/1210FIT401_94/\"\n",
    "\n",
    "\n",
    "#De Rompert level Column: “005 de Rompert” *.csv\n",
    "path15 = \"../data/sewer_data_db/data_pump_level/\"\n",
    "#De Rompert flow + Maasport\n",
    "path16 = \"../data/sewer_data_db/data_pump_flow/1210FIT501_99/\"\n",
    "\n",
    "#Location linkage\n",
    "path_linkinfo = \"../data/sewer_model\"\n",
    "path_rain = \"../data/sewer_data/rain_timeseries\"\n",
    "\n",
    "#Missing Engelerschans (in map also)\n",
    "station_names = [\"Haarsteeg\", \"Bokhoven\", \"Hertogenbosch (Helftheuvelweg)\",\n",
    "                 \"Hertogenbosch (Rompert)\", \"Hertogenbosch (Oude Engelenseweg)\",\n",
    "                 \"Hertogenbosch (Maasport)\"]\n",
    "\n",
    "flow_paths = [path1, path2, path4, path6, path8, path10, path12, path14, path16]\n",
    "level_paths = [path3, path5, path7, path9, path11, path13, path15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_bag(flow, level, station_names):\n",
    "    #station_to_flow = dict()\n",
    "    #station_to_level = dict()\n",
    "    return None\n",
    "\n",
    "\n",
    "def streets_rain(station_names, path_linkinfo, path_rain):\n",
    "    \n",
    "    link = pd.read_excel(path_linkinfo+\n",
    "                   \"/20180717_dump riodat rioleringsdeelgebieden_matched_to_rainfall_locations.xlsx\",\n",
    "                   header = 9)\n",
    "    \n",
    "    rain = pd.concat([pd.read_csv(file, header = 2) for file in glob.glob(path_rain+\"/*.*\")], ignore_index = True)\n",
    "    \n",
    "    #Street names by stations\n",
    "    streets = [list(link[(link[\"Naam kern\"] == name)][\"Naam / lokatie\"]) for name in station_names]\n",
    "\n",
    "    #Streets that are not found in rainfall data belonging to Hertogenbosch (Oude Engelenseweg)\n",
    "    excl = ['Pettelaarpark', 'Geb. 16 Paleiskwartier']\n",
    "\n",
    "    for s in streets:\n",
    "        try:\n",
    "            for i in excl:\n",
    "                s.remove(i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "\n",
    "    #All the rain for the streets for the pump stations in order of station_names and the streets per station\n",
    "    #can be found in streets nested list in the same order\n",
    "    station_to_rain = rain[[\"Begin\", \"Eind\"] + [i for sl in streets for i in sl]]\n",
    "\n",
    "    station_rain = pd.DataFrame()\n",
    "    for i in range(len(station_names)):\n",
    "        station_rain[station_names[i]] = rain[streets[i]].sum(1)\n",
    "\n",
    "    station_rain[\"Begin\"] =  station_to_rain[\"Begin\"]\n",
    "    station_rain[\"End\"] = station_to_rain[\"Eind\"]\n",
    "    station_rain[\"Begin\"] = pd.to_datetime(station_rain[\"Begin\"])\n",
    "    station_rain[\"End\"] = pd.to_datetime(station_rain[\"End\"])\n",
    "    station_rain[\"date\"] = station_rain[\"Begin\"].dt.date\n",
    "    return station_rain.sort_values(by=[\"Begin\"])\n",
    "\n",
    "def labeler3(dayrain, previousdayrain):\n",
    "    \"\"\"\n",
    "    Classifies a whole day as dry if previous OR the same day has less than 0.05\n",
    "    \"\"\"\n",
    "    if dayrain <= 0.05 or previousdayrain <= 0.05:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "def rainyday(df, station_names):\n",
    "    \"\"\"\n",
    "    Returns a list with DFs per station for dry day classification\n",
    "    \"\"\"\n",
    "    df_rainyday = df.groupby(df[\"Begin\"].dt.date).sum().reset_index(drop=False)\n",
    "    \n",
    "    events_df = []\n",
    "    \n",
    "    for i in station_names:\n",
    "        df_relevant = df_rainyday[[i, \"Begin\"]]\n",
    "        df_relevant[\"previousday\"] = df_relevant[i].shift(-1)\n",
    "        df_relevant[\"dryday\"] = df_relevant.apply(lambda x: labeler3(x[i], x[\"previousday\"]), axis=1)\n",
    "        events_df.append(df_relevant)\n",
    "        \n",
    "    return events_df\n",
    "    \n",
    "\n",
    "def labeler2(rain):\n",
    "    \"\"\"\n",
    "    Classifies an hour as dry if there hasn't been rain previous n days days\n",
    "    \"\"\"\n",
    "    threshold = 0.05*(5/8)\n",
    "    if rain >= 0 and rain <= threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def last_n_cumsum(n, name, df):\n",
    "    B = []\n",
    "    i =0\n",
    "    n_lim = n\n",
    "    station = list(df[name])\n",
    "    while i<len(station):\n",
    "        if i<n_lim:\n",
    "            B.append(sum(station[0:i]))\n",
    "        if i>=n_lim:\n",
    "            B.append(sum(station[i-n_lim:i]))\n",
    "        i=i+1\n",
    "    return B\n",
    "\n",
    "def binary_rain(station_names, df, n):\n",
    "    \n",
    "    binary_rain_df = []\n",
    "    df = df.sort_values(by=\"Begin\")\n",
    "    df = df.set_index(\"Begin\", drop = False).resample(\"60Min\").sum()\n",
    "    df = df.reset_index(drop=False)\n",
    "    \n",
    "    for i in station_names:\n",
    "        df_relevant = df[[i, \"Begin\"]]\n",
    "        df_relevant[\"cumsum_previous_15\"] = last_n_cumsum(n, i, df)\n",
    "        df_relevant[\"rain_-15_class\"] = df_relevant.apply(lambda x: labeler2(x[\"cumsum_previous_15\"]), axis=1)\n",
    "        binary_rain_df.append(df_relevant)\n",
    "    return binary_rain_df\n",
    "\n",
    "# Here n = 15\n",
    "#events_df = rain_events2(station_names, df, 15)\n",
    "\n",
    "\n",
    "counter = 0\n",
    "def labeler(rain, previous_rain):\n",
    "    \"\"\"\n",
    "    Labels rain events (events are defined as consecutive measurements where there is no stop of rain)\n",
    "    (Previous definition)\n",
    "    \"\"\"\n",
    "    global counter\n",
    "    if rain == 0:\n",
    "        return \"None\"\n",
    "    else:\n",
    "        if previous_rain == 0:\n",
    "            counter += 1\n",
    "            return counter\n",
    "        if previous_rain != 0:\n",
    "            return counter\n",
    "        \n",
    "def rain_events(station_names, df):\n",
    "    events_df = []\n",
    "    df = df.sort_values(by=\"Begin\")\n",
    "    \n",
    "    for i in station_names:\n",
    "        df_relevant = df[[i, \"Begin\", \"End\"]]\n",
    "        df_relevant[\"instr\"] = df_relevant[i].shift()\n",
    "        df_relevant[\"rain_event_ID\"] = df_relevant.apply(lambda x: labeler(x[i], x[\"instr\"]), axis=1)\n",
    "        df_relevant.drop(columns=[\"instr\"], inplace=True)\n",
    "        events_df.append(df_relevant)\n",
    "    return events_df\n",
    "\n",
    "#events_df = rain_events(station_names, df)\n",
    "\n",
    "def group_by_event(events_df, station_name, rain_event_col, k):\n",
    "    df = events_df[k]\n",
    "    \n",
    "    #Filtering rain events where there was no rain\n",
    "    df = df[df[rain_event_col] != \"None\"]\n",
    "    \n",
    "    #should be elsewhere\n",
    "    df[\"End\"] = pd.to_datetime(df[\"End\"])\n",
    "    #\n",
    "    \n",
    "    #Converting duration of individual measurements to minutes\n",
    "    df[\"duration\"] = (df[\"End\"] - df[\"Begin\"]).dt.total_seconds()/60\n",
    "    \n",
    "    #Filter measurements that last more than 1 week (there are errors in data)\n",
    "    df = df[(df[\"duration\"] <= 10080) & (df[\"duration\"] >= 0)]\n",
    "    \n",
    "    #Group by rain event ID and sum the durations and rain measurements\n",
    "    df = df[[\"duration\", station_name, rain_event_col]].groupby(rain_event_col).sum()\n",
    "    return df\n",
    "\n",
    "\n",
    "def bound_dates(df1, df2, df1_datecol, df2_datecol):\n",
    "    \n",
    "    # Making sure both have the same range of dates\n",
    "    df1[df1_datecol] = pd.to_datetime(df1[df1_datecol])\n",
    "    df2[df2_datecol] = pd.to_datetime(df2[df2_datecol])\n",
    "    \n",
    "    df1 = pd.merge(left=df1, left_on=df1_datecol,\n",
    "         right=df2, right_on=df2_datecol)\n",
    "    #d2 = pd.merge(left=df2, left_on=df2_datecol,\n",
    "    #     right=df1, right_on=df1_datecol)\n",
    "    df1.drop(columns=[df2_datecol])\n",
    "    return df1\n",
    "\n",
    "def hourly_conversion(path, mean=bool):\n",
    "    \"\"\"\n",
    "    Converts data to hourly format\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.concat([pd.read_csv(file) for file in glob.glob(path+\"/*.*\")], ignore_index = True)\n",
    "    df = df[[\"datumBeginMeting\", \"datumEindeMeting\", \"hstWaarde\"]].sort_values(by='datumBeginMeting')\n",
    "    df[\"datumBeginMeting\"] = pd.to_datetime(df[\"datumBeginMeting\"])\n",
    "    df[\"datumEindeMeting\"] = pd.to_datetime(df[\"datumEindeMeting\"])\n",
    "    if mean == True:\n",
    "        df = df.set_index(\"datumBeginMeting\", drop = False).resample(\"60Min\").mean()\n",
    "    else:\n",
    "        df = df.set_index(\"datumBeginMeting\", drop = False).resample(\"60Min\").sum()\n",
    "   \n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "    \n",
    "rain_df = streets_rain(station_names, path_linkinfo, path_rain)\n",
    "hourly_rain_classified = binary_rain(station_names, rain_df, n=15)\n",
    "\n",
    "\n",
    "\n",
    "flow_bokhoven = hourly_conversion(path4, mean = False)\n",
    "flow_bokhoven  = bound_dates(flow_bokhoven, hourly_rain_classified[1], \"datumBeginMeting\", \"Begin\")\n",
    "\n",
    "# flow_bokhoven.to_csv('../data/Bokhoven_rain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rain in each station df\n",
    "rain_df = streets_rain(station_names, path_linkinfo, path_rain)\n",
    "\n",
    "# List of dfs with each station's hourly rain classification in order of station_names list,\n",
    "# with n = 15. (n=15 means rain_-15_class is \"0\" if no rain prior 15 hours and \"1\" otherwise)\n",
    "hourly_rain_classified = binary_rain(station_names, rain_df, n=15)\n",
    "\n",
    "# Level and flow of Haarsteeg per hour (shapes match here, have to check if they do on other files,\n",
    "# otherwise bound dates like in line 86)\n",
    "level_haarsteeg = hourly_conversion(path5, mean = True)\n",
    "flow_haarsteeg = hourly_conversion(path6, mean = False)\n",
    "\n",
    "# Returns merged dataframe with the timestamps present in both dfs\n",
    "flow_haarsteeg  = bound_dates(flow_haarsteeg, hourly_rain_classified[0], \"datumBeginMeting\", \"Begin\")\n",
    "\n",
    "nl_holidays = holidays.CountryHoliday('NL')\n",
    "\n",
    "def binary_holidays(country_holidays, dates):\n",
    "    holiday = []\n",
    "    for i in dates:\n",
    "        if i in nl_holidays:\n",
    "            holiday.append(1)\n",
    "        else:\n",
    "            holiday.append(0)\n",
    "    return holiday\n",
    "    \n",
    "\n",
    "\n",
    "def feature_setup(df_flow, df_level, country_holidays):\n",
    "    \n",
    "    dates = df_flow[\"Begin\"]\n",
    "    flow = df_flow[\"hstWaarde\"]\n",
    "    rained_n_class = df_flow[\"rain_-15_class\"]\n",
    "    rain = df_flow[\"Haarsteeg\"]\n",
    "    #cumsum_previous_n = df_flow[\"cumsum_previous_15\"]\n",
    "    level = df_level[\"hstWaarde\"]\n",
    "    holidays = binary_holidays(nl_holidays, dates)\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    features[\"day_ofthe_month\"] = dates.dt.day\n",
    "    features[\"hour\"] = dates.dt.hour\n",
    "    features[\"day_ofthe_year\"] = dates.dt.dayofyear\n",
    "    features[\"day_ofthe_week\"] = dates.dt.dayofweek\n",
    "    features[\"holiday\"] = holidays\n",
    "    features[\"flow\"] = flow\n",
    "    \n",
    "    # Add feature of amount of rain some timestamps before or during this hour (5 minute stamps)\n",
    "    features[\"rain_hour\"] = rain\n",
    "    \n",
    "    # Add a feature of level at previous timestamps before or during this hour (5 minute stamps)\n",
    "    features[\"level\"] = level\n",
    "    \n",
    "    #Not actual features, but columns by which we will filter prediction procedures\n",
    "    #(Be sure to remove them before fitting)\n",
    "    features[\"rain_N_ago\"] = rained_n_class\n",
    "    features[\"dates\"] = dates\n",
    "    \n",
    "\n",
    "    return features\n",
    "\n",
    "df_features = feature_setup(flow_haarsteeg, level_haarsteeg, nl_holidays)\n",
    "\n",
    "\n",
    "def mse(d):\n",
    "    \"\"\"Mean Squared Error\"\"\"\n",
    "    return mean(d * d) \n",
    "\n",
    "# def random_forest(features):\n",
    "#     features = features[df_features['rain_N_ago'] == 0]\n",
    "    \n",
    "#     all_days = set(features[\"dates\"].dt.date)\n",
    "#     test_days = random.sample(all_days, 120)\n",
    "#     training_days = [x for x in all_days if x not in test_days]\n",
    "    \n",
    "#     training = features[features[\"dates\"].dt.date.isin(training_days)]\n",
    "#     training_X = training.drop(columns = [\"flow\", \"dates\"])\n",
    "#     training_Y = training[\"flow\"]\n",
    "    \n",
    "#     testing = features[features[\"dates\"].dt.date.isin(test_days)]\n",
    "#     testing_X = testing.drop(columns = [\"flow\", \"dates\"])\n",
    "#     testing_Y = testing[\"flow\"]\n",
    "    \n",
    "#     rf = RandomForestRegressor(n_estimators = 1000)\n",
    "#     rf.fit(training_X, training_Y)\n",
    "#     prediction = rf.predict(testing_X)\n",
    "#     error = testing_Y - prediction\n",
    "#     return print(rf.feature_importances_, sqrt(mse(error)))\n",
    "    \n",
    "\n",
    "# random_forest(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_rain_pump = pd.read_pickle(\"../data/combined_data/combined_rain_pump_1hour_mean.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bokhoven</th>\n",
       "      <th>Engelerschans</th>\n",
       "      <th>Helftheuvelweg</th>\n",
       "      <th>Maaspoort</th>\n",
       "      <th>Oude Engelenseweg</th>\n",
       "      <th>de Rompert</th>\n",
       "      <th>Haarsteeg</th>\n",
       "      <th>RG8180_flow</th>\n",
       "      <th>RG8180_level</th>\n",
       "      <th>RG8170_flow</th>\n",
       "      <th>RG8170_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datumBeginMeting</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.028333</td>\n",
       "      <td>3657.320000</td>\n",
       "      <td>-0.308333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>0.376667</td>\n",
       "      <td>3356.713333</td>\n",
       "      <td>-0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>2755.048333</td>\n",
       "      <td>-1.198333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>2394.443333</td>\n",
       "      <td>-1.273333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bokhoven  Engelerschans  Helftheuvelweg  Maaspoort  \\\n",
       "datumBeginMeting                                                          \n",
       "2017-12-31 23:00:00    0.0000         0.0000          0.0000     0.0000   \n",
       "2018-01-01 00:00:00    0.0264         0.0000          0.0000     0.0000   \n",
       "2018-01-01 01:00:00    0.0224         0.0119          0.0198     0.0038   \n",
       "2018-01-01 02:00:00    0.0675         0.0057          0.0069     0.0374   \n",
       "2018-01-01 03:00:00    0.0273         0.0032          0.0078     0.0262   \n",
       "\n",
       "                     Oude Engelenseweg  de Rompert  Haarsteeg  RG8180_flow  \\\n",
       "datumBeginMeting                                                             \n",
       "2017-12-31 23:00:00             0.0000      0.0000     0.0000          NaN   \n",
       "2018-01-01 00:00:00             0.0000      0.0000     0.0000    20.000000   \n",
       "2018-01-01 01:00:00             0.0000      0.0006     0.0636    15.666667   \n",
       "2018-01-01 02:00:00             0.0265      0.0311     0.0172     0.000000   \n",
       "2018-01-01 03:00:00             0.0014      0.0377     0.0215     4.666667   \n",
       "\n",
       "                     RG8180_level  RG8170_flow  RG8170_level  \n",
       "datumBeginMeting                                              \n",
       "2017-12-31 23:00:00           NaN          NaN           NaN  \n",
       "2018-01-01 00:00:00      1.028333  3657.320000     -0.308333  \n",
       "2018-01-01 01:00:00      0.376667  3356.713333     -0.846667  \n",
       "2018-01-01 02:00:00      0.160000  2755.048333     -1.198333  \n",
       "2018-01-01 03:00:00      0.061667  2394.443333     -1.273333  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_rain_pump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_to_supervised(combined_rain_pump)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
